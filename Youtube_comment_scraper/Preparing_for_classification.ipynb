{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the comments dataset\n",
    "comments_df = pd.read_csv(\"comments.csv\")\n",
    "sample_size = 300\n",
    "comment_sample = comments_df.sample(n=sample_size, random_state=42)\n",
    "comment_sample.to_csv(\"comment_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"comment_sample.csv\")\n",
    "label_counts = df[\"Label\"].value_counts()\n",
    "\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sample Labeling for Testing\n",
    "\n",
    "In preparation for testing my fine-tuned DistilBERT model, I manually labeled a sample of 300 YouTube comments. The labeling process involved categorizing comments into three sentiment classes: 2 for neutral, 1 for positive, and 0 for negative. However, as the model was fine-tuned specifically for positive and negative sentiment analysis, I plan to remove the neutral class during evaluation to focus on the target sentiments.\n",
    "\n",
    "The positive and negative sentiment classes turned out to be randomly distributed, with approximately equal weighting. In the sample, there were 72 positive comments and 77 negative comments, while the remaining comments were labeled as neutral. This labeled sample will be used to assess the model's performance on YouTube comments, providing valuable insights into its ability to classify sentiments effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.drop(columns=\"Comment ID\")\n",
    "\n",
    "df_test = df_test[df_test[\"Label\"] != 2]\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Extracting the comments from the test dataset\n",
    "youtube_comments = df_test[\"Comment\"].tolist()\n",
    "\n",
    "# Tokenizing the YouTube comments using the same tokinzer\n",
    "tokenized_youtube_comments = tokenizer(\n",
    "    youtube_comments,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=103,\n",
    "    return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "# Extracing input IDs and attenetion mask for the test dataset\n",
    "input_ids_test = tokenized_youtube_comments[\"input_ids\"]\n",
    "attention_mask_test = tokenized_youtube_comments[\"attention_mask\"]\n",
    "\n",
    "# Adding tokenized data to the original DataFrame for the test dataset\n",
    "df_test[\"input_ids\"] = input_ids_test.numpy().tolist()\n",
    "df_test[\"attention_mask\"] = attention_mask_test.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting input IDs and attention masks from the DataFrame\n",
    "input_ids_test = df_test[\"input_ids\"].tolist()\n",
    "attention_mask_test = df_test[\"attention_mask\"].tolist()\n",
    "\n",
    "# Converting lists to TensorFlow tensors\n",
    "input_ids_tensor = tf.convert_to_tensor(input_ids_test, dtype=tf.int32)\n",
    "attention_mask_tensor = tf.convert_to_tensor(attention_mask_test, dtype=tf.int32)\n",
    "\n",
    "# Displaying the shapes of the tensors\n",
    "print(\"Input IDs Tensor Shape:\", input_ids_tensor.shape)\n",
    "print(\"Attention Mask Tensor Shape:\", attention_mask_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../NLP_model/best_sentiment_model\"\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuned DistilBERT model, specifically trained for binary sentiment classification, is then loaded, retaining its task-specific configuration. This enables the model to predict sentiment based on its training with similar data.\n",
    "\n",
    "In the subsequent sections, the loaded DistilBERT model is applied to predict sentiment in the prepared YouTube comments. The analysis aims to reveal insights into the model's effectiveness in discerning sentiment within the context of user-generated content on the YouTube platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_model.signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the best model\n",
    "\n",
    "infer = loaded_model.signatures[\"serving_default\"]\n",
    "\n",
    "predictions = infer(\n",
    "    input_ids=input_ids_tensor,\n",
    "    attention_mask=attention_mask_tensor\n",
    ")\n",
    "\n",
    "logits = predictions[\"dense\"]\n",
    "\n",
    "# Converting logits to probabilites using softmax\n",
    "probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "# Getting the predicted label values\n",
    "predicted_labels = tf.argmax(probabilities, axis=-1)\n",
    "\n",
    "print(\"Predicted Labels:\", predicted_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, idx, count = tf.unique_with_counts(predicted_labels)\n",
    "\n",
    "for label, count in zip(y.numpy(), count.numpy()):\n",
    "    print(f\"Label {label}: {count} occurences\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
